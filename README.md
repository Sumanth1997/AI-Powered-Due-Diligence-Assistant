# üîç AI-Powered Due Diligence Assistant

An AI-powered platform that automates pitch deck analysis for venture capital due diligence. Upload a pitch deck and get a comprehensive report with extracted claims, fact-checked verification, and critical analysis‚Äîall powered by multi-agent AI.

![Sago Architecture](docs/images/architecture_diagram.png)

## ÔøΩ Screenshots

### Analysis Dashboard
![Analysis](docs/images/Analysis.png)

### Investor Management
![Investors](docs/images/investor.png)

### Email Integration
![Gmail](docs/images/Email.png)

## ‚ú® Features

- **üìÑ Pitch Deck Analysis** - Upload PDF or text files for automated analysis
- **ü§ñ Multi-Agent AI Pipeline** - Three specialized agents work together:
  - **Scribe** - Extracts specific, verifiable claims
  - **Researcher** - Fact-checks claims via web search
  - **Analyst** - Generates critical due diligence report
- **üìß Gmail Integration** - Scan inbox for pitch deck emails and analyze directly
- **üë§ Investor Profiles** - Personalized analysis based on investment thesis
- **‚ö° Async Processing** - Redis-powered job queue for non-blocking analysis
- **üé® Modern UI** - React + TypeScript frontend with dark theme

## üì¶ Sample Input & Output

### Sample Input
Use the included sample pitch deck to test the system:
- **`mock_pitch_deck.txt`** - Shopify pitch deck (text format, included in repo)
- **`shopify-pitch-deck.pdf`** - Shopify pitch deck (PDF format, included in repo)

### Sample Output
See `docs/sample_output.md` for a complete analysis report. Key sections include:

**Extracted Claims:**
```
‚Ä¢ Active Shopify Merchants: 200,000+
‚Ä¢ Gross Merchandise Volume (GMV) in Q3 '15: $1.9B+
‚Ä¢ Global Total Addressable Market (TAM): $46B
```

**Verification Results:**
```
‚Ä¢ 200,000+ merchants ‚Üí CONTRADICTED (now 2M+ as of 2023)
‚Ä¢ $1.9B GMV Q3'15 ‚Üí CONFIRMED (official financial reports)
‚Ä¢ $46B TAM ‚Üí UNVERIFIED (requires methodology review)
```

**Red Flags Identified:**
```
‚Ä¢ Vague metrics ("200,000+" lacks precision)
‚Ä¢ Vanity metrics (GMV vs. actual revenue)
‚Ä¢ Celebrity endorsements as social proof (misleading)
‚Ä¢ Aggressive TAM estimates
```


## üìã Prerequisites

- **Go** 1.21+
- **Python** 3.13+
- **Node.js** 22+
- **Docker** & Docker Compose
- **API Keys** (see below)

## üîë Required API Keys

| Service | Purpose | Get Key |
|---------|---------|---------|
| **OpenAI** | LLM for analysis | [platform.openai.com](https://platform.openai.com/api-keys) |
| **Serper** | Web search for verification | [serper.dev](https://serper.dev) |
| **Pinecone** (optional) | Vector DB for investor memory | [pinecone.io](https://www.pinecone.io) |
| **Gmail OAuth** (optional) | Email integration | [Google Cloud Console](https://console.cloud.google.com) |

## üöÄ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/Sumanth1997/AI-Powered-Due-Diligence-Assistant.git
cd AI-Powered-Due-Diligence-Assistant
```

### 2. Start Infrastructure (PostgreSQL + Redis)

```bash
docker compose up -d
```

This starts:
- PostgreSQL on `localhost:5433`
- Redis on `localhost:6380`

### 3. Initialize the Database

```bash
# Run the migration script
docker exec -i sago-postgres psql -U sago -d sago < backend-go/db/migrations/001_init.sql
```

### 4. Configure Environment Variables

```bash
# Copy the example env file
cp engine-python/.env.example engine-python/.env

# Edit with your API keys
nano engine-python/.env
```

**Required variables:**
```env
# OpenAI API Key (required)
OPENAI_API_KEY=sk-...

# Serper API Key (required for fact-checking)
SERPER_API_KEY=your-serper-key

# Database (default works with docker-compose)
DATABASE_URL=postgresql://sago:sago_dev_password@localhost:5433/sago

# Redis (default works with docker-compose)
REDIS_URL=redis://localhost:6380
```

### 5. Start the Go Backend

```bash
cd backend-go
go mod download
go build -o sago && ./sago
```

You should see:
```
Database connected successfully
Redis queue connected
‚á® http server started on [::]:8080
```

### 6. Start the Python Worker

```bash
cd engine-python
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python worker.py
```

You should see:
```
[Worker] Starting job worker, listening on sago:jobs...
[Worker] Redis: redis://localhost:6380
```

### 7. Start the Frontend

```bash
cd frontend
npm install
npm run dev
```

Open **http://localhost:5173** in your browser! üéâ

## üìñ Usage

### Upload a Pitch Deck

1. Go to http://localhost:5173
2. Click **Analysis** tab
3. Drag & drop a PDF or TXT file
4. Watch the analysis progress in real-time

### Create an Investor Profile (Optional)

1. Click **Investors** tab
2. Click **+ New**
3. Fill in:
   - Email & Name
   - Investment Thesis
   - Focus Areas (tags)
   - Deal Breakers (red flags)
4. Select the investor before uploading for personalized analysis

### Gmail Integration (Optional)

1. Set up Gmail OAuth (see below)
2. Click **Gmail** tab
3. Click **üîÑ Refresh** to scan inbox
4. Click **Analyze** on any pitch deck email

## üìß Gmail OAuth Setup (Optional)

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create a new project or select existing
3. Enable the **Gmail API**
4. Configure OAuth consent screen
5. Create OAuth 2.0 credentials (Desktop app)
6. Download as `credentials.json` and place in `backend-go/`
7. Restart the backend - it will prompt for authentication

## üóÇÔ∏è Project Structure

```
AI-Powered-Due-Diligence-Assistant/
‚îú‚îÄ‚îÄ backend-go/           # Go API server
‚îÇ   ‚îú‚îÄ‚îÄ main.go           # Entry point & routes
‚îÇ   ‚îú‚îÄ‚îÄ db/               # Database models & migrations
‚îÇ   ‚îú‚îÄ‚îÄ queue/            # Redis job queue
‚îÇ   ‚îú‚îÄ‚îÄ gmail/            # Gmail integration
‚îÇ   ‚îî‚îÄ‚îÄ storage/          # GCS client (optional)
‚îú‚îÄ‚îÄ engine-python/        # Python AI worker
‚îÇ   ‚îú‚îÄ‚îÄ worker.py         # Redis job consumer
‚îÇ   ‚îú‚îÄ‚îÄ agents/           # CrewAI agents
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scribe.py     # Claim extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ researcher.py # Web verification
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ analyst.py    # Due diligence report
‚îÇ   ‚îî‚îÄ‚îÄ personalization/  # Investor memory (Pinecone)
‚îú‚îÄ‚îÄ frontend/             # React + TypeScript UI
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx       # Main component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts        # Backend API client
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ index.css     # Styling
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.ts    # Dev server config
‚îî‚îÄ‚îÄ docker-compose.yml    # PostgreSQL + Redis
```

## üõ†Ô∏è API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Service health check |
| POST | `/decks/upload` | Upload pitch deck for analysis |
| GET | `/jobs/:id` | Get job status and report |
| GET | `/investors` | List investor profiles |
| POST | `/investors` | Create investor profile |
| GET | `/gmail/check` | Scan Gmail for pitch decks |
| POST | `/gmail/process/:id` | Analyze Gmail pitch deck |

## üîß Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `OPENAI_API_KEY` | ‚úÖ | - | OpenAI API key |
| `SERPER_API_KEY` | ‚úÖ | - | Serper search API key |
| `DATABASE_URL` | ‚úÖ | - | PostgreSQL connection string |
| `REDIS_URL` | ‚úÖ | - | Redis connection string |
| `PINECONE_API_KEY` | ‚ùå | - | Pinecone for investor memory |
| `PINECONE_INDEX` | ‚ùå | - | Pinecone index name |
| `GCS_BUCKET` | ‚ùå | - | GCS bucket for file storage |

### Using Different LLMs

The system supports multiple LLM providers. Edit `engine-python/agents/scribe.py`:

```python
# OpenAI (default)
LLM(model="openai/gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))

# Google Gemini
LLM(model="gemini/gemini-2.0-flash", api_key=os.getenv("GOOGLE_API_KEY"))

# Local Ollama
LLM(model="ollama/llama3.2", base_url="http://localhost:11434")
```

## üê≥ Docker Deployment

Build and run all services with Docker Compose:

```bash
# Build images
docker compose -f docker-compose.prod.yml build

# Start all services
docker compose -f docker-compose.prod.yml up -d
```

## üìä Cost Estimates

| Service | Cost |
|---------|------|
| OpenAI GPT-4o-mini | ~$0.01 per analysis |
| Serper API | Free tier: 2,500 searches/month |
| Pinecone | Free tier: 100K vectors |
| PostgreSQL | Self-hosted (free) |
| Redis | Self-hosted (free) |

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

## üìù License

MIT License - see [LICENSE](LICENSE) for details.

## üôè Acknowledgments

- [CrewAI](https://github.com/joaomdmoura/crewai) - Multi-agent framework
- [Echo](https://echo.labstack.com/) - Go web framework
- [Vite](https://vitejs.dev/) - Frontend build tool
