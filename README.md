# ğŸ” Sago - AI-Powered Due Diligence Assistant

An AI-powered platform that automates pitch deck analysis for venture capital due diligence. Upload a pitch deck and get a comprehensive report with extracted claims, fact-checked verification, and critical analysisâ€”all powered by multi-agent AI.

![Sago Architecture](docs/images/architecture_diagram.png)

## âœ¨ Features

- **ğŸ“„ Pitch Deck Analysis** - Upload PDF or text files for automated analysis
- **ğŸ¤– Multi-Agent AI Pipeline** - Three specialized agents work together:
  - **Scribe** - Extracts specific, verifiable claims
  - **Researcher** - Fact-checks claims via web search
  - **Analyst** - Generates critical due diligence report
- **ğŸ“§ Gmail Integration** - Scan inbox for pitch deck emails and analyze directly
- **ğŸ‘¤ Investor Profiles** - Personalized analysis based on investment thesis
- **âš¡ Async Processing** - Redis-powered job queue for non-blocking analysis
- **ğŸ¨ Modern UI** - React + TypeScript frontend with dark theme

## ğŸ“¦ Sample Input & Output

### Sample Input
Use the included sample pitch deck to test the system:
- **`mock_pitch_deck.txt`** - Shopify pitch deck (text format, included in repo)
- **`shopify-pitch-deck.pdf`** - Shopify pitch deck (PDF format, included in repo)

### Sample Output
See `docs/sample_output.md` for a complete analysis report. Key sections include:

**Extracted Claims:**
```
â€¢ Active Shopify Merchants: 200,000+
â€¢ Gross Merchandise Volume (GMV) in Q3 '15: $1.9B+
â€¢ Global Total Addressable Market (TAM): $46B
```

**Verification Results:**
```
â€¢ 200,000+ merchants â†’ CONTRADICTED (now 2M+ as of 2023)
â€¢ $1.9B GMV Q3'15 â†’ CONFIRMED (official financial reports)
â€¢ $46B TAM â†’ UNVERIFIED (requires methodology review)
```

**Red Flags Identified:**
```
â€¢ Vague metrics ("200,000+" lacks precision)
â€¢ Vanity metrics (GMV vs. actual revenue)
â€¢ Celebrity endorsements as social proof (misleading)
â€¢ Aggressive TAM estimates
```


## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚â”€â”€â”€â”€â–¶â”‚   Go Backend    â”‚â”€â”€â”€â”€â–¶â”‚  Python Worker  â”‚
â”‚  localhost:5173 â”‚     â”‚  localhost:8080 â”‚     â”‚    (CrewAI)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚                        â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                    â”‚                     â”‚            â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”‚
              â”‚ PostgreSQL â”‚        â”‚   Redis    â”‚â—€â”€â”€â”€â”€â”˜
              â”‚   :5433    â”‚        â”‚   :6380    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- **Go** 1.21+
- **Python** 3.13+
- **Node.js** 22+
- **Docker** & Docker Compose
- **API Keys** (see below)

## ğŸ”‘ Required API Keys

| Service | Purpose | Get Key |
|---------|---------|---------|
| **OpenAI** | LLM for analysis | [platform.openai.com](https://platform.openai.com/api-keys) |
| **Serper** | Web search for verification | [serper.dev](https://serper.dev) |
| **Pinecone** (optional) | Vector DB for investor memory | [pinecone.io](https://www.pinecone.io) |
| **Gmail OAuth** (optional) | Email integration | [Google Cloud Console](https://console.cloud.google.com) |

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/AI-Powered-Due-Diligence-Assistant.git
cd AI-Powered-Due-Diligence-Assistant
```

### 2. Start Infrastructure (PostgreSQL + Redis)

```bash
docker compose up -d
```

This starts:
- PostgreSQL on `localhost:5433`
- Redis on `localhost:6380`

### 3. Initialize the Database

```bash
# Run the migration script
docker exec -i sago-postgres psql -U sago -d sago < backend-go/db/migrations/001_init.sql
```

### 4. Configure Environment Variables

```bash
# Copy the example env file
cp engine-python/.env.example engine-python/.env

# Edit with your API keys
nano engine-python/.env
```

**Required variables:**
```env
# OpenAI API Key (required)
OPENAI_API_KEY=sk-...

# Serper API Key (required for fact-checking)
SERPER_API_KEY=your-serper-key

# Database (default works with docker-compose)
DATABASE_URL=postgresql://sago:sago_dev_password@localhost:5433/sago

# Redis (default works with docker-compose)
REDIS_URL=redis://localhost:6380
```

### 5. Start the Go Backend

```bash
cd backend-go
go mod download
go build -o sago && ./sago
```

You should see:
```
Database connected successfully
Redis queue connected
â‡¨ http server started on [::]:8080
```

### 6. Start the Python Worker

```bash
cd engine-python
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python worker.py
```

You should see:
```
[Worker] Starting job worker, listening on sago:jobs...
[Worker] Redis: redis://localhost:6380
```

### 7. Start the Frontend

```bash
cd frontend
npm install
npm run dev
```

Open **http://localhost:5173** in your browser! ğŸ‰

## ğŸ“– Usage

### Upload a Pitch Deck

1. Go to http://localhost:5173
2. Click **Analysis** tab
3. Drag & drop a PDF or TXT file
4. Watch the analysis progress in real-time

### Create an Investor Profile (Optional)

1. Click **Investors** tab
2. Click **+ New**
3. Fill in:
   - Email & Name
   - Investment Thesis
   - Focus Areas (tags)
   - Deal Breakers (red flags)
4. Select the investor before uploading for personalized analysis

### Gmail Integration (Optional)

1. Set up Gmail OAuth (see below)
2. Click **Gmail** tab
3. Click **ğŸ”„ Refresh** to scan inbox
4. Click **Analyze** on any pitch deck email

## ğŸ“§ Gmail OAuth Setup (Optional)

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create a new project or select existing
3. Enable the **Gmail API**
4. Configure OAuth consent screen
5. Create OAuth 2.0 credentials (Desktop app)
6. Download as `credentials.json` and place in `backend-go/`
7. Restart the backend - it will prompt for authentication

## ğŸ—‚ï¸ Project Structure

```
AI-Powered-Due-Diligence-Assistant/
â”œâ”€â”€ backend-go/           # Go API server
â”‚   â”œâ”€â”€ main.go           # Entry point & routes
â”‚   â”œâ”€â”€ db/               # Database models & migrations
â”‚   â”œâ”€â”€ queue/            # Redis job queue
â”‚   â”œâ”€â”€ gmail/            # Gmail integration
â”‚   â””â”€â”€ storage/          # GCS client (optional)
â”œâ”€â”€ engine-python/        # Python AI worker
â”‚   â”œâ”€â”€ worker.py         # Redis job consumer
â”‚   â”œâ”€â”€ agents/           # CrewAI agents
â”‚   â”‚   â”œâ”€â”€ scribe.py     # Claim extraction
â”‚   â”‚   â”œâ”€â”€ researcher.py # Web verification
â”‚   â”‚   â””â”€â”€ analyst.py    # Due diligence report
â”‚   â””â”€â”€ personalization/  # Investor memory (Pinecone)
â”œâ”€â”€ frontend/             # React + TypeScript UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx       # Main component
â”‚   â”‚   â”œâ”€â”€ api.ts        # Backend API client
â”‚   â”‚   â””â”€â”€ index.css     # Styling
â”‚   â””â”€â”€ vite.config.ts    # Dev server config
â””â”€â”€ docker-compose.yml    # PostgreSQL + Redis
```

## ğŸ› ï¸ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Service health check |
| POST | `/decks/upload` | Upload pitch deck for analysis |
| GET | `/jobs/:id` | Get job status and report |
| GET | `/investors` | List investor profiles |
| POST | `/investors` | Create investor profile |
| GET | `/gmail/check` | Scan Gmail for pitch decks |
| POST | `/gmail/process/:id` | Analyze Gmail pitch deck |

## ğŸ”§ Configuration

### Environment Variables

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `OPENAI_API_KEY` | âœ… | - | OpenAI API key |
| `SERPER_API_KEY` | âœ… | - | Serper search API key |
| `DATABASE_URL` | âœ… | - | PostgreSQL connection string |
| `REDIS_URL` | âœ… | - | Redis connection string |
| `PINECONE_API_KEY` | âŒ | - | Pinecone for investor memory |
| `PINECONE_INDEX` | âŒ | - | Pinecone index name |
| `GCS_BUCKET` | âŒ | - | GCS bucket for file storage |

### Using Different LLMs

The system supports multiple LLM providers. Edit `engine-python/agents/scribe.py`:

```python
# OpenAI (default)
LLM(model="openai/gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))

# Google Gemini
LLM(model="gemini/gemini-2.0-flash", api_key=os.getenv("GOOGLE_API_KEY"))

# Local Ollama
LLM(model="ollama/llama3.2", base_url="http://localhost:11434")
```

## ğŸ³ Docker Deployment

Build and run all services with Docker Compose:

```bash
# Build images
docker compose -f docker-compose.prod.yml build

# Start all services
docker compose -f docker-compose.prod.yml up -d
```

## ğŸ“Š Cost Estimates

| Service | Cost |
|---------|------|
| OpenAI GPT-4o-mini | ~$0.01 per analysis |
| Serper API | Free tier: 2,500 searches/month |
| Pinecone | Free tier: 100K vectors |
| PostgreSQL | Self-hosted (free) |
| Redis | Self-hosted (free) |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open a Pull Request

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- [CrewAI](https://github.com/joaomdmoura/crewai) - Multi-agent framework
- [Echo](https://echo.labstack.com/) - Go web framework
- [Vite](https://vitejs.dev/) - Frontend build tool